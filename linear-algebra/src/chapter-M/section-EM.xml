<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="section-EM">
    <title>Elementary Matrices</title>

    <introduction>
        There is an alternative characterization of row reduction, which provides helpful insights. In fact, performing row reduction on a matrix <m>A</m> is equivalent to multiplying <m>A</m> by particular matrices, called <em>elementary matrices</em>.
    </introduction>

    <subsection>
        <title>Matrix-Vector Product and Matrix Multiplication from the Row Perspective</title>
        <p>
            There is another characterization of the matrix-vector product, and matrix multiplication, from the perspective of the rows of the matrix, and in particular a linear combination of the rows. Let <m>A</m> be an <m>m \times n</m> matrix. Recall that <m>A\vec{x}</m> (where <m>\vec{x} \in \mathbb{R}^n</m>) can be thought of as a linear combination of the columns of <m>A</m> with weights given by the entries of <m>\vec{x}</m>. In a similar way, the product <m>\vec{x}A</m> (where <m>\vec{x} \in \mathbb{R}^m</m>) can be thought of as a linear combination of the rows of <m>A</m>, with weights given by the entries of <m>\vec{x}</m>. 
        </p>
        <p>
            More precisely, let <m>\vec{x} = (x_1, \dots, x_m)</m>, and let <m>\vec{a}^i</m> denote the <m>i</m>th row of <m>A</m>, so
        </p>
        <me>
            A = \begin{bmatrix} \vec{a}^1 \\ \vdots \\ \vec{a}^m \end{bmatrix}
        </me>
        <p>
            Note that we haven't defined matrix powers, so this is not ambiguous. Then,
        </p>
        <me>
            \vec{x} A = x_1 \vec{a}^1 + \dots + x_m \vec{a}^m
        </me>
        <p>
            for which the result is again a row vector.
        </p>

        <example>
            <p>
                For example,
            </p>
            <md>
                <mrow>\begin{bmatrix} 2 \amp -1 \end{bmatrix} \begin{bmatrix} 2 \amp 3 \\ -1 \amp 4 \end{bmatrix} \amp = 2 \begin{bmatrix} 2 \amp 3 \end{bmatrix} - 1 \begin{bmatrix} -1 \amp 4 \end{bmatrix}</mrow>
                <mrow>\amp = \begin{bmatrix} 4 \amp 6 \end{bmatrix} + \begin{bmatrix} 1 \amp -4 \end{bmatrix}</mrow>
                <mrow>\amp = \begin{bmatrix} 5 \amp 2 \end{bmatrix}</mrow>
            </md>
        </example>

        <p>
            Then, this leads to a characterization of matrix multiplication. Let <m>B</m> be an <m>n \times p</m> matrix. Then,
        </p>
        <me>
            \boxed{AB = \begin{bmatrix} \vec{a}^1 B \\ \vdots \\ \vec{a}^m B \end{bmatrix}}
        </me>
        <p>
            That is, each row of <m>AB</m> is a linear combination of the rows of <m>B</m>, with weights given by the correspondsing row of <m>A</m>.
        </p>
        <example>
            <p>
                For example,
            </p>
            <md>
                <mrow>\begin{bmatrix} 1 \amp 0 \\ 0 \amp 1 \end{bmatrix} \begin{bmatrix} 5 \amp 2 \\ -2 \amp 4 \end{bmatrix} \amp = \begin{bmatrix} 1 \cdot \begin{bmatrix} 5 \amp 2 \end{bmatrix} + 0 \cdot \begin{bmatrix} -2 \amp 4 \end{bmatrix} \\ 0 \cdot \begin{bmatrix} 5 \amp 2 \end{bmatrix} + 1 \cdot \begin{bmatrix} -2 \amp 4 \end{bmatrix} \end{bmatrix}</mrow>
                <mrow>\amp = \begin{bmatrix} 5 \amp 2 \\ -2 \amp 4 \end{bmatrix}</mrow>
            </md>
        </example>
    </subsection>

    <subsection>
        <title>Elementary Matrices</title>
        <p>
            Using the row perspective on matrix multiplication, we can characterize the elementary row operation as multiplication by a matrix.
        </p>
        
        <p>
            Consider the case of a <m>2 \times 2</m> matrix,
        </p>
        <me>
            A = \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix}
        </me>
        <p>
            To multiply the top row by a scalar <m>k</m>, we can multiply by the matrix,
        </p>
        <me>
            \begin{bmatrix} k \amp 0 \\ 0 \amp 1 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} ka \amp kb \\ c \amp d \end{bmatrix}
        </me>
        From the row perspective, the first row <m>\begin{bmatrix} k \amp 0 \end{bmatrix}</m> means that the first row of the product involving taking <m>k</m> times the first row of <m>A</m>, and <m>0</m> times the second row of <m>A</m>. Similarly,
        <me>
            \begin{bmatrix} 1 \amp 0 \\ 0 \amp k \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} a \amp b \\ kc \amp kd \end{bmatrix}
        </me>
        <p>
            To interchange the two rows, again consider the matrix,
        </p>
        <me>
            \begin{bmatrix} 0 \amp 1 \\ 1 \amp 0 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} c \amp d \\ a \amp b \end{bmatrix}
        </me>
        <p>
            Again, from the row perspective, the first row <m>\begin{bmatrix} 0 \amp 1 \end{bmatrix}</m> means taking 0 of the first row and 1 of the second row, to get <m>\begin{bmatrix} c \amp d \end{bmatrix}</m>.
        </p>
        <p>
            For row replacement, that is, adding to one row a multiple of another row, again we use a linear combination. Suppose we want to add <m>k R_2</m> to <m>R_1</m>. In other words, <m>R_1 + kR_2 \rightarrow R_1</m>. Then,
        </p>
        <me>
            \begin{bmatrix} 1 \amp k \\ 0 \amp 1 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} a + kc \amp b + kd \\ c \amp d \end{bmatrix}
        </me>

        <p>
            These patterns and reasoning with row combinations generalize to arbitrary matrices. The idea is, the effect of a single row operation can be captured by left-multiplication by a matrix which is like the identity matrix, but slightly different. 
        </p>
        <p>
            In particular, the matrix that represents a particular elementary row operation is found by performing the same row operation on the identity matrix. 
        </p>

        <definition>
            An <term>elementary matrix</term> is a matrix which is obtained by performing a single elementary row operation on an identity matrix.
        </definition>
    
        <theorem>
            <p>
                Let <m>A</m> be an <m>m \times n</m> matrix. If an elementary row operation is performed on <m>A</m>, the resulting matrix can be written as <m>EA</m> for an <m>m \times n</m> elementary matrix <m>E</m> formed by performing the same row operation on <m>I_m</m>.
            </p>
        </theorem>
    
        <p>
            In other words, every elementary row operation corresponds to left-multiplication by some elementary matrix.
        </p>

        <p>
            In addition, every elementary matrix is invertible, intuitively because row operations are reversable. If <m>E</m> corresponds to some row operation, then the reverse operation has a corresponding elementary matrix <m>F</m> such that <m>EF = FE = I</m>. 
        </p>

        <p>
            In summary,
        </p>
    
        <theorem>
            <p>Every elementary matrix <m>E</m> is invertible, and the inverse of <m>E</m> is the elementary matrix of the same type as <m>E</m> which transforms <m>E</m> back into <m>I</m>.</p>
        </theorem>
    </subsection>

    <subsection>
        <title>Elementary Matrices and Matrix Inverses</title>
        <p>
            Elementary matrices provide insight into finding inverses of matrices.
        </p>

        <theorem>
            <p>An <m>n \times n</m> matrix <m>A</m> is invertible if and only if <m>A</m> is row equivalent to <m>I_n</m>, and in this case, any sequence of row operations that reduces <m>A</m> to <m>I_n</m> also transforms <m>I_n</m> into <m>A^{-1}</m>.</p>
        </theorem>

        <proof>
            <p>
                If <m>A</m> is invertible, then the equation <m>A\vec{x} = \vec{b}</m> has a solution for every <m>\vec{b}</m>, and <m>A</m> has a pivot position in every row (<m>n</m> rows). Since <m>A</m> is square (in particular has <m>n</m> columns), this implies that the pivor positions are on the main diagonal. Thus, the RREF of <m>A</m> is <m>I_n</m>, or <m>A \sim I_n</m>.
            </p>
            <p>
                Conversely, suppose that <m>A \sim I_n</m>. Then, each step in the row reduction of <m>A</m> correspond to left-multiplication by some elementary matrix. Say there are <p>p</p> steps to reduce <m>A</m> to <m>I_n</m>, with corresponding elementary matrices <m>E_1, \dots, E_p</m> such that,
            </p>
            <me>
                A \sim E_1 A \sim E_2 (E_1 A) \sim \cdots \sim E_p(E_{p-1} \cdots E_1 A) = I_n
            </me>
            In other words,
            <me>
                E_p \cdots E_1 A = I_n
            </me>
            In other words, the matrix <m>E_p \cdots E_1</m> multiplies with <m>A</m> to produce the identity $matrix. Thus, <m>A^{-1} = E_p \cdots E_1</m>. Equvialently, <m>A^{-1} = E_p \cdots E_1 I_n</m>, i.e. <m>A^{-1}</m> is obtained by applying <m>E_1, \dots, E_p</m> successively to <m>I_n</m>, in the same sequence requried to transform <m>A</m> to <m>I_n</m>.
        </proof>

        <p>
            The previous theorem leads to an algorithm for determining matrix inverses,
        </p>

        <theorem>
            <p>To determine the inverse of a square matrix <m>A</m>,</p>
                <ol>
                    <li>Form the augmented matrix <m>\begin{bmatrix} A \mid I \end{bmatrix}</m>.</li>
                    <li>Perform row reduction on the augmented matrix <m>\begin{bmatrix} A \mid I \end{bmatrix}</m></li>
                    <li>If <m>A</m> is row equivalent to <m>I</m>, then the augmented matrix in RREF will be of the form <m>\begin{bmatrix} I \mid B \end{bmatrix}</m>. Then, <m>B = A^{-1}</m>.</li>
                    <li>Otherwise, if <m>A</m> is not row equivalent to <m>A</m>, then <m>A</m> does not have an inverse.</li>
                </ol>
        </theorem>

        <p>
            After using this procedure, the result can be verified by checking that <m>AA^{-1} = I</m>.
        </p>

    </subsection>

    <exercises>
        <exercise>
            <statement>
                In Python, implement a program to compute the inverse of an arbitrary square matrix (this will use the RREF program).
            </statement>
        </exercise>
    </exercises>

</section>
