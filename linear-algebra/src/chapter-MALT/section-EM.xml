<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="section-EM">
    <title>Elementary Matrices</title>

    <introduction>
        Row reduction and elimination can be alternatively characterized in terms of matrix multiplication. In particular, performing row reduction on a matrix <m>A</m> is equivalent to multiplying <m>A</m> by particular matrices, called <em>elementary matrices</em>.
    </introduction>

    <subsection>
        <title>Elementary Matrices</title>
        <p>
            Using the row perspective on matrix multiplication, we can characterize the elementary row operation as multiplication by a matrix.
        </p>
        
        <p>
            Consider the case of a <m>2 \times 2</m> matrix,
        </p>
        <me>
            A = \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix}
        </me>
        <p>
            To multiply the top row by a scalar <m>k</m>, we can multiply by the matrix,
        </p>
        <me>
            \begin{bmatrix} k \amp 0 \\ 0 \amp 1 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} ka \amp kb \\ c \amp d \end{bmatrix}
        </me>
        From the row perspective, the first row <m>\begin{bmatrix} k \amp 0 \end{bmatrix}</m> means that the first row of the product involving taking <m>k</m> times the first row of <m>A</m>, and <m>0</m> times the second row of <m>A</m>. Similarly,
        <me>
            \begin{bmatrix} 1 \amp 0 \\ 0 \amp k \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} a \amp b \\ kc \amp kd \end{bmatrix}
        </me>
        <p>
            To interchange the two rows, again consider the matrix,
        </p>
        <me>
            \begin{bmatrix} 0 \amp 1 \\ 1 \amp 0 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} c \amp d \\ a \amp b \end{bmatrix}
        </me>
        <p>
            Again, from the row perspective, the first row <m>\begin{bmatrix} 0 \amp 1 \end{bmatrix}</m> means taking 0 of the first row and 1 of the second row, to get <m>\begin{bmatrix} c \amp d \end{bmatrix}</m>.
        </p>
        <p>
            For row replacement, that is, adding to one row a multiple of another row, again we use a linear combination. Suppose we want to add <m>k R_2</m> to <m>R_1</m>. In other words, <m>R_1 + kR_2 \rightarrow R_1</m>. Then,
        </p>
        <me>
            \begin{bmatrix} 1 \amp k \\ 0 \amp 1 \end{bmatrix} \begin{bmatrix} a \amp b \\ c \amp d \end{bmatrix} = \begin{bmatrix} a + kc \amp b + kd \\ c \amp d \end{bmatrix}
        </me>

        <p>
            These patterns and reasoning with row combinations generalize to arbitrary matrices. The idea is, the effect of a single row operation can be captured by left-multiplication by a matrix which is a slightly modified version of the identity matrix. In particular, the matrix that represents a particular elementary row operation is found by performing the same row operation on the identity matrix. 
        </p>

        <definition>
            An <term>elementary matrix</term> is a matrix which is obtained by performing a single elementary row operation on an identity matrix.
        </definition>
    
        <theorem>
            <p>
                Let <m>A</m> be an <m>m \times n</m> matrix. If an elementary row operation is performed on <m>A</m>, the resulting matrix can be written as <m>EA</m> for an <m>m \times n</m> elementary matrix <m>E</m> formed by performing the same row operation on <m>I_m</m>.
            </p>
        </theorem>
    
        <p>
            In other words, every elementary row operation corresponds to left-multiplication by some elementary matrix.
        </p>

        <p>
            In addition, every elementary matrix is invertible, intuitively because row operations are reversable. If <m>E</m> corresponds to some row operation, then the reverse operation has a corresponding elementary matrix <m>F</m> such that <m>EF = FE = I</m>.
        </p>

        <p>
            In summary,
        </p>
    
        <theorem>
            <p>Every elementary matrix <m>E</m> is invertible, and the inverse of <m>E</m> is the elementary matrix of the same type as <m>E</m> which transforms <m>E</m> back into <m>I</m>.</p>
        </theorem>

    </subsection>

    <subsection>
        <title>Permutation Matrices for Row Exchanges</title>
        <p>
            The elementary matrices for row exchanges are the identity matrix with two row exchanged. For example, for <m>2 \times 2</m> matrices, there are 2 rows, so there is only 1 possible row exchange, represented by the matrix,
        </p>
        <me>
            \begin{bmatrix} 0 \amp 1 \\ 1 \amp 0 \end{bmatrix}
        </me>
        <p>
            For <m>3 \times 3</m> matrices, there are 3 rows, and so <m>3</m> possible pairs of rows to exchange (<m>(1,2), (1,3)</m>, and <m>(2,3)</m>), represented by the matrices,
        </p>
        <me>
            \begin{array}{ccc}
            (1,2) \amp (1,3) \amp (2,3) \\
            \begin{bmatrix} 0 \amp 1 \amp 0 \\ 1 \amp 0 \amp 0 \\ 0 \amp 0 \amp 1 \end{bmatrix} \amp \begin{bmatrix} 0 \amp 0 \amp 1 \\ 0 \amp 1 \amp 0 \\ 1 \amp 0 \amp 0 \end{bmatrix} \amp \begin{bmatrix} 1 \amp 0 \amp 0 \\ 0 \amp 0 \amp 1 \\ 0 \amp 1 \amp 0 \end{bmatrix}
            \end{array}
        </me>

        <p>
            In general, among <m>n \times n</m> matrices, there are <m>n!</m> permutation matrices.
        </p>
    </subsection>


</section>
