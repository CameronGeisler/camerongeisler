\documentclass[letterpaper,12pt]{article}
\input{preamble}

\chead{Introduction to Linear Transformations}

\begin{document}

A matrix equation can arise by considering a matrix $A$ as an object that ``acts" on a vector $\vec{x}$ to produce a new vector $A\vec{x}$. In other words, matrices can be thought of as a map or function from one set of vectors to another. In particular, a map from $\mathbb{R}^n$ to $\mathbb{R}^m$. This is a generalization of a real-valued function.

\begin{definition}
A \textbf{transformation} (or \textbf{mapping}) $T$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ is a rule which assigns to each vector $\vec{x} \in \mathbb{R}^n$ a vector $T(\vec{x})$ in $\mathbb{R}^m$.
\begin{itemize}
    \item The set $\mathbb{R}^n$ is called the \textbf{domain} of $T$ (more generally, a subset of $\mathbb{R}^n$, denoted by $D(T)$), and $\mathbb{R}^m$ is called the \textbf{codomain} of $T$.
    \item For $\vec{x} \in \mathbb{R}^n$, the vector $T(\vec{x})$ is called the \textbf{image} of $\vec{x}$.
    \item The \textbf{range} of $T$ is the set of all images $T(\vec{x})$.
\end{itemize}
\end{definition}

\section*{Matrix Transformations}
If $A$ is an $m \times n$ matrix, then matrix multiplication by $A$ is a transformation. In particular, the map $T(\vec{x}) = A\vec{x}$ is a transformation from $\mathbb{R}^n$ to $\mathbb{R}^m$.

\section*{Linear Transformations}
Recall that if $A$ is an $m \times n$ matrix, and $\vec{u}, \vec{v} \in \mathbb{R}^n$, then
\begin{equation*}
    A(\vec{u} + \vec{v}) = A\vec{u} + A\vec{v} \quad \text{and} \quad A(c\vec{u}) = cA\vec{u}
\end{equation*}

These properties together make matrix multiplication a ``linear" transformation, and are one of the most important properties in linear algebra.

\begin{definition}
A transformation $T$ is \textbf{linear} if
\begin{enumerate}[(a)]
    \item $T(\vec{u} + \vec{v}) = T(\vec{u}) + T(\vec{v})$ for all $\vec{u}, \vec{v} \in D(T)$.
    \item $T(c\vec{u}) = cT(\vec{u})$ for all $c \in \mathbb{R}, \vec{u} \in D(T)$.
\end{enumerate}
\end{definition}

With this definition, every matrix transformation is a linear transformation. Linear transformations are said to be \textbf{operation preserving}, in particular preserving the operations of addition and scalar multiplication. This is because for a linear map, adding $\vec{u} + \vec{v}$ in $\mathbb{R}^n$ and then applying $T$ is equivalent to applying $T$ to $\vec{u}$ and $\vec{v}$ and then adding their result in $\mathbb{R}^m$.

\begin{theorem}
\textbf{Maps 0 to 0}. If $T$ is a linear transformation, then $T(\vec{0}) = \vec{0}$.
\end{theorem}
\begin{proof}
By linearity, $T(\vec{0}) = T(0\vec{u}) = 0 \cdot T(\vec{u}) = \vec{0}$.
\end{proof}

\begin{theorem}
\textbf{General linear property}. Let $T$ be a linear transformation, $\vec{v}_1, \dots, \vec{v}_n \in D(T)$, $a_1, \dots, a_n \in \mathbb{R}$. Then,
\begin{equation*}
    \boxed{T(a_1 \vec{v}_1 + \dots + a_n \vec{v}_n) = a_1 T(\vec{v}_1) + \dots + a_n T(\vec{v}_n)}
\end{equation*}
More compactly,
\begin{equation*}
    T\brac{\sum_{k=1}^n a_k \vec{v}_k} = \sum_{k=1}^n a_k T(\vec{v}_k)
\end{equation*}
\end{theorem}



\end{document}